#Feature selection in Random Forest (Backward Selection)
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- rfe(df.train[,-(which(colnames(df) == "left"))], df.train$left, sizes = c(1:4), rfeControl = control, verbose = TRUE)
results
print(results)
plot(results)
ggplot(data = results) +geom_line(size = 1)
ggplot(data = results) + geom_line(size = 1) + geom_smooth()
print(results, type = c("g", "o"))
print(results)
plot(results, type=c("g", "o"))
ggplot(data = results) + geom_line()
model.rf <- randomForest::randomForest(left ~ satisfaction_level + number_project + average_montly_hours + time_spend_company
+ last_evaluation, data = df.train, verbose = TRUE)
df.train$predicted_outcome <- predict(model.rf, newdata = df.train)
df.test$predicted_outcome <- predict(model.rf, newdata = df.test)
#Confusion matrices
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#IMPROVING THE MODEL
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
#Feature selection in Random Forest (Backward Selection)
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df) == "left"))], df.train$left, sizes = c(1:4), rfeControl = control, verbose = TRUE)
results <- caret::rfe(df.train[,-(which(colnames(df) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
rm(list = ls())
a <- c(2,3,4)
b <- c(1,2)
a * b
c <- c("x", "y")
rm(list = ls())
library(caret)
library(ggplot2)
library(dummies)
library(pROC)
library(randomForest)
#Importing dataset
df <- read.csv("HR_data.csv", header = TRUE)
#Renaming columns and cleaning the dataset
colnames(df)[colnames(df) == "sales"] <- "department"
#Creating factors and partitions
df$department <- as.factor(df$department)
df$salary <- as.factor(df$salary)
df$left <- as.factor(df$left)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
#Logistic regression without feature selection
fit1 <- glm(left ~ ., data = df.train, family = "binomial")
df.train$predicted_prob <- predict(fit1, df.train, type = "response")
df.test$predicted_prob <- predict(fit1, df.test, type = "response")
#Classification with cutoff=0.5
df.train$predicted_outcome <- ifelse((df.train$predicted_prob > 0.5), 1, 0)
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
df.test$predicted_outcome <- ifelse((df.test$predicted_prob > 0.5), 1, 0)
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#ROC for Logistic regerssion with all predictors
roc.train <- pROC::roc(df.train$left, df.train$predicted_prob)
pROC::plot.roc(roc.train)
roc.test1 <- pROC::roc(df.test$left, df.test$predicted_prob)
pROC::plot.roc(roc.test1)
#Plot cutoff vs accuracy
cutoff <- seq(0, 1, length = 10000)
acc <- numeric(10000)
accPlot.dataFrame <- data.frame(CUTOFF = cutoff, ACCURACY = acc)
#Plot for training data set
for (index in 1:10000) {
pred <- ifelse((df.train$predicted_prob > cutoff[index]), 1, 0)
true.positives <- sum(pred == 1 & df.train$left == 1)
true.negatives <- sum(pred == 0 & df.train$left == 0)
accPlot.dataFrame$ACCURACY[index] <- ((true.positives + true.negatives) / length(df.train$left)) * 100
}
ggplot2::ggplot(data = accPlot.dataFrame, mapping = aes(x = CUTOFF, y = ACCURACY, col)) + geom_line(size = 1)
idealCutoff <- accPlot.dataFrame$CUTOFF[which.max(accPlot.dataFrame$ACCURACY)]
acc.max <- accPlot.dataFrame$ACCURACY[which.max(accPlot.dataFrame$ACCURACY)]
accData <- data.frame(CUTOFF = idealCutoff, ACCURACY = acc.max)
#Plot for test data set
for (index in 1:10000) {
pred <- ifelse((df.test$predicted_prob > cutoff[index]), 1, 0)
true.positives <- sum(pred == 1 & df.test$left == 1)
true.negatives <- sum(pred == 0 & df.test$left == 0)
accPlot.dataFrame$ACCURACY[index] <- ((true.positives + true.negatives) / length(df.test$left)) * 100
}
ggplot2::ggplot(data = accPlot.dataFrame, mapping = aes(x = CUTOFF, y = ACCURACY, col)) + geom_line(size = 1)
idealCutoff <- accPlot.dataFrame$CUTOFF[which.max(accPlot.dataFrame$ACCURACY)]
acc.max <- accPlot.dataFrame$ACCURACY[which.max(accPlot.dataFrame$ACCURACY)]
accData <- rbind.data.frame(accData, c(idealCutoff, acc.max), make.row.names = FALSE)
row.names(accData) <- c("TRAINING", "TEST")
print(accData)
#Confusion matrices with optimal cutoff
df.train$predicted_outcome <- ifelse((df.train$predicted_prob > accData$CUTOFF[rownames(accData) == "TRAINING"]), 1, 0)
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
df.test$predicted_outcome <- ifelse((df.test$predicted_prob > accData$CUTOFF[rownames(accData) == "TEST"]), 1, 0)
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
View(df.train)
#FEATURE SELECTION
#Rank features by importance
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
#Without dummy variables
control <- caret::trainControl(method = "repeatedcv", number = 10, repeats = 3)
model <- caret::train(left~., data = df.train, method = "glm", trControl = control)
importance <- caret::varImp(model)
plot(importance)
fit2 <- glm(left ~ satisfaction_level + time_spend_company + Work_accident + salary + number_project
+ average_montly_hours, data = df.train, family = "binomial")
df.train$predicted_prob <- predict(fit2, df.train, type = "response")
df.test$predicted_prob <- predict(fit2, df.test, type = "response")
#ROC for Logistic regerssion with selected predictors without dummy variables
roc.train <- pROC::roc(df.train$left, df.train$predicted_prob)
pROC::plot.roc(roc.train)
roc.test1 <- pROC::roc(df.test$left, df.test$predicted_prob)
pROC::plot.roc(roc.test1)
#Plot cutoff vs accuracy
cutoff <- seq(0, 1, length = 10000)
acc <- numeric(10000)
accPlot.dataFrame <- data.frame(CUTOFF = cutoff, ACCURACY = acc)
#Plot for training data set
for (index in 1:10000) {
pred <- ifelse((df.train$predicted_prob > cutoff[index]), 1, 0)
true.positives <- sum(pred == 1 & df.train$left == 1)
true.negatives <- sum(pred == 0 & df.train$left == 0)
accPlot.dataFrame$ACCURACY[index] <- ((true.positives + true.negatives) / length(df.train$left)) * 100
}
ggplot2::ggplot(data = accPlot.dataFrame, mapping = aes(x = CUTOFF, y = ACCURACY, col)) + geom_line(size = 1)
idealCutoff <- accPlot.dataFrame$CUTOFF[which.max(accPlot.dataFrame$ACCURACY)]
acc.max <- accPlot.dataFrame$ACCURACY[which.max(accPlot.dataFrame$ACCURACY)]
accData <- data.frame(CUTOFF = idealCutoff, ACCURACY = acc.max)
#Plot for test data set
for (index in 1:10000) {
pred <- ifelse((df.test$predicted_prob > cutoff[index]), 1, 0)
true.positives <- sum(pred == 1 & df.test$left == 1)
true.negatives <- sum(pred == 0 & df.test$left == 0)
accPlot.dataFrame$ACCURACY[index] <- ((true.positives + true.negatives) / length(df.test$left)) * 100
}
ggplot2::ggplot(data = accPlot.dataFrame, mapping = aes(x = CUTOFF, y = ACCURACY, col)) + geom_line(size = 1)
idealCutoff <- accPlot.dataFrame$CUTOFF[which.max(accPlot.dataFrame$ACCURACY)]
acc.max <- accPlot.dataFrame$ACCURACY[which.max(accPlot.dataFrame$ACCURACY)]
accData <- rbind.data.frame(accData, c(idealCutoff, acc.max), make.row.names = FALSE)
row.names(accData) <- c("TRAINING", "TEST")
print(accData)
#Confusion matrices with optimal cutoff
df.train$predicted_outcome <- ifelse((df.train$predicted_prob > accData$CUTOFF[rownames(accData) == "TRAINING"]), 1, 0)
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
df.test$predicted_outcome <- ifelse((df.test$predicted_prob > accData$CUTOFF[rownames(accData) == "TEST"]), 1, 0)
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#With dummy variables
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
dum.colnames <- c("department", "salary")
df.train <- dummy.data.frame(data = df.train, names = dum.colnames, sep = "_")
df.test <- dummy.data.frame(data = df.test, names = dum.colnames, sep = "_")
control <- caret::trainControl(method = "repeatedcv", number = 10, repeats = 3)
model <- caret::train(left~., data = df.train, method = "glm", trControl = control)
importance <- caret::varImp(model)
plot(importance)
fit3 <- glm(left ~ satisfaction_level + time_spend_company + Work_accident + salary_low + number_project + salary_high
+ average_montly_hours, data = df.train, family = "binomial")
df.train$predicted_prob <- predict(fit3, df.train, type = "response")
df.test$predicted_prob <- predict(fit3, df.test, type = "response")
#ROC for Logistic regerssion with selected predictors with dummy variables
roc.train <- pROC::roc(df.train$left, df.train$predicted_prob)
pROC::plot.roc(roc.train)
roc.test1 <- pROC::roc(df.test$left, df.test$predicted_prob)
pROC::plot.roc(roc.test1)
#Plot cutoff vs accuracy
cutoff <- seq(0, 1, length = 10000)
acc <- numeric(10000)
accPlot.dataFrame <- data.frame(CUTOFF = cutoff, ACCURACY = acc)
#Plot for training data set
for (index in 1:10000) {
pred <- ifelse((df.train$predicted_prob > cutoff[index]), 1, 0)
true.positives <- sum(pred == 1 & df.train$left == 1)
true.negatives <- sum(pred == 0 & df.train$left == 0)
accPlot.dataFrame$ACCURACY[index] <- ((true.positives + true.negatives) / length(df.train$left)) * 100
}
ggplot2::ggplot(data = accPlot.dataFrame, mapping = aes(x = CUTOFF, y = ACCURACY, col)) + geom_line(size = 1)
idealCutoff <- accPlot.dataFrame$CUTOFF[which.max(accPlot.dataFrame$ACCURACY)]
acc.max <- accPlot.dataFrame$ACCURACY[which.max(accPlot.dataFrame$ACCURACY)]
accData <- data.frame(CUTOFF = idealCutoff, ACCURACY = acc.max)
#Plot for test data set
for (index in 1:10000) {
pred <- ifelse((df.test$predicted_prob > cutoff[index]), 1, 0)
true.positives <- sum(pred == 1 & df.test$left == 1)
true.negatives <- sum(pred == 0 & df.test$left == 0)
accPlot.dataFrame$ACCURACY[index] <- ((true.positives + true.negatives) / length(df.test$left)) * 100
}
ggplot2::ggplot(data = accPlot.dataFrame, mapping = aes(x = CUTOFF, y = ACCURACY, col)) + geom_line(size = 1)
idealCutoff <- accPlot.dataFrame$CUTOFF[which.max(accPlot.dataFrame$ACCURACY)]
acc.max <- accPlot.dataFrame$ACCURACY[which.max(accPlot.dataFrame$ACCURACY)]
accData <- rbind.data.frame(accData, c(idealCutoff, acc.max), make.row.names = FALSE)
row.names(accData) <- c("TRAINING", "TEST")
print(accData)
#Confusion matrices with optimal cutoff
df.train$predicted_outcome <- ifelse((df.train$predicted_prob > accData$CUTOFF[rownames(accData) == "TRAINING"]), 1, 0)
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
df.test$predicted_outcome <- ifelse((df.test$predicted_prob > accData$CUTOFF[rownames(accData) == "TEST"]), 1, 0)
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
View(df.train)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
print(results)
ggplot(data = results) + geom_line()
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], size = c(1:9) df.train$left, rfeControl = control, verbose = TRUE)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], size = c(1:9), df.train$left, rfeControl = control, verbose = TRUE)
print(results)
ggplot(data = results) + geom_line()
df.train[,-(which(colnames(df.train) == "left"))
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, rfeControl = control, verbose = TRUE)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], size = c(1:9), df.train$left, rfeControl = control, verbose = TRUE)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], size = c(1:9), df.train$left, rfeControl = control,
method = "glm", verbose = TRUE)
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, size = c(1:9), df.train$left,
rfeControl = control, verbose = TRUE)
#Feature selection in Random Forest (Backward Selection)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
print(results)
ggplot(data = results) + geom_line()
model.rf <- randomForest::randomForest(left ~ satisfaction_level + number_project + average_montly_hours + time_spend_company
+ last_evaluation, data = df.train, verbose = TRUE)
df.train$predicted_outcome <- predict(model.rf, newdata = df.train)
df.test$predicted_outcome <- predict(model.rf, newdata = df.test)
#Confusion matrices
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 8)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
control <- caret::rfeControl(functions = lmFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
control <- caret::rfeControl(functions = caretFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
#Feature selection via Backward Selection for Logistic Rgression (Recursive Feature Elimination)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = caretFuncs, method = "cv", rerank = TRUE, number = 10)
control <- caret::rfeControl(functions = lmFuncs, method = "cv", rerank = TRUE, number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
rm(list = ls())
setwd("~/GitHub/Employee-attrition-prediction")
library(caret)
library(ggplot2)
library(dummies)
library(pROC)
library(randomForest)
#Importing dataset
df <- read.csv("HR_data.csv", header = TRUE)
#Renaming columns and cleaning the dataset
colnames(df)[colnames(df) == "sales"] <- "department"
#Creating factors and partitions
df$department <- as.factor(df$department)
df$salary <- as.factor(df$salary)
df$left <- as.factor(df$left)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
#Exploring collinearity and covariance
cor.matrix <- cor(df.train)
#Exploring collinearity and covariance
dum.colnames <- c("department", "salary")
df.train <- dummy.data.frame(data = df.train, names = dum.colnames, sep = "_")
df.test <- dummy.data.frame(data = df.test, names = dum.colnames, sep = "_")
cor.matrix <- cor(df.train)
View(df.train)
install.packages("Hmisc")
library(Hmisc)
cor.matrix <- Hmisc::rcorr(as.matrix(df.train))
cor.matrix
install.packages("corrplot")
corrplot::corrplot(cor.matrix)
str(cor.matrix)
corrplot::corrplot(as.matrix(cor.matrix))
corrplot::corrplot(as.matrix(cor.matrix), na.rm = TRUE)
plot(cor.matrix)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
cor.matrix <- Hmisc::rcorr(as.matrix(df.train))
#Exploring collinearity and covariance
dum.colnames <- c("department", "salary")
df.train <- dummy.data.frame(data = df.train, names = dum.colnames, sep = "_")
df.test <- dummy.data.frame(data = df.test, names = dum.colnames, sep = "_")
#Exploring collinearity and covariance
dum.colnames <- c("department", "salary")
df.train <- dummy.data.frame(data = df.train, names = dum.colnames, sep = "_")
df.test <- dummy.data.frame(data = df.test, names = dum.colnames, sep = "_")
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
#Exploring collinearity and covariance
dum.colnames <- c("department", "salary")
df.train <- dummy.data.frame(data = df.train, names = dum.colnames, sep = "_")
df.test <- dummy.data.frame(data = df.test, names = dum.colnames, sep = "_")
cor.matrix <- Hmisc::rcorr(as.matrix(df.train))
print(cor.matrix)
findCorrelation(cor.matrix, cutoff = 0.7)
findCorrelation(as.matrix(cor.matrix), cutoff = 0.7)
cor(df.train)
cor(as.numeric(df.train))
cor.matrix <- Hmisc::rcorr(as.matrix(df.train[,-(which(colnames(df.train) == "left"))]), df.train$left)
print(cor.matrix)
cor.matrix <- Hmisc::rcorr(df.train$left)
cor.matrix <- Hmisc::rcorr(df.train$left, df.train[,-(which(colnames(df.train) == "left"))])
cor.matrix <- Hmisc::rcorr(df.train)
cor.matrix <- Hmisc::rcorr(as.matrix(df.train$left))
print(cor.matrix)
cor.matrix <- Hmisc::rcorr(as.matrix(df.train$left), as.matrix(df.train[,-(which(colnames(df.train) == "left"))]))
print(cor.matrix)
cor.matrix <- Hmisc::rcorr(as.matrix(df.train))
print(cor.matrix)
cor.matrix <- as.matrix(cor.matrix)
print(cor.matrix)
cor.matrix
cor.matrix <- Hmisc::rcorr(as.matrix(df.train))
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
cor.matrix <- cor(df)
cor.matrix <- cor(df.train)
str(df.train)
#Exploring collinearity and covariance
dum.colnames <- c("department", "salary")
df.train <- dummy.data.frame(data = df.train, names = dum.colnames, sep = "_")
df.test <- dummy.data.frame(data = df.test, names = dum.colnames, sep = "_")
str(df.train)
cor(df.train)
cor.matrix <- Hmisc::rcorr(as.matrix(df.train))
print(cor.matrix)
cor.matrix <- as.matrix(as.numeric(cor.matrix))
rm(list = ls())
library(randomForest)
library(Hmisc)
library(corrplot)
#Importing dataset
df <- read.csv("HR_data.csv", header = TRUE)
#Renaming columns and cleaning the dataset
colnames(df)[colnames(df) == "sales"] <- "department"
#Creating factors and partitions(based on department)
df$department <- as.factor(df$department)
df$salary <- as.factor(df$salary)
df$left <- as.factor(df$left)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
#Logistic regression without feature selection
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
fit1 <- glm(left ~ ., data = df.train, family = "binomial")
fit1
summary(fit1)
plot(fit1)
ggplot(data = fit1, mapping = aes(x = fit1$fitted.values, y = fit1$residuals)) + geom_point()
df.train$predicted_prob <- predict(fit1, df.train, type = "response")
df.test$predicted_prob <- predict(fit1, df.test, type = "response")
#Classification with cutoff=0.5
df.train$predicted_outcome <- ifelse((df.train$predicted_prob > 0.5), 1, 0)
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
df.test$predicted_outcome <- ifelse((df.test$predicted_prob > 0.5), 1, 0)
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#ROC for Logistic regerssion with all predictors
roc.train <- pROC::roc(df.train$left, df.train$predicted_prob)
pROC::plot.roc(roc.train)
roc.test1 <- pROC::roc(df.test$left, df.test$predicted_prob)
pROC::plot.roc(roc.test1)
rm(list = ls())
library(caret)
library(ggplot2)
library(dummies)
library(pROC)
library(randomForest)
#Importing dataset
df <- read.csv("HR_data.csv", header = TRUE)
#Renaming columns and cleaning the dataset
colnames(df)[colnames(df) == "sales"] <- "department"
#Creating factors and partitions
df$department <- as.factor(df$department)
df$salary <- as.factor(df$salary)
df$left <- as.factor(df$left)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
str(df)
str(df.train)
#Random Forests
model.rf <- randomForest::randomForest(left ~ ., data = df.train, verbose = TRUE)
df.train$predicted_outcome <- predict(model.rf, newdata = df.train)
df.test$predicted_outcome <- predict(model.rf, newdata = df.test)
#Confusion matrices
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
#Feature selection in Random Forest (Backward Selection)
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
conf.matrix.test
#Feature selection in Random Forest (Backward Selection)
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
print(results)
#Feature selection in Random Forest (Backward Selection)
set.seed(123457)
train_index <- caret::createDataPartition(df$department, p = 0.7, list = FALSE)
df.train <- df[train_index,]
df.test <- df[-train_index,]
control <- caret::rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- caret::rfe(df.train[,-(which(colnames(df.train) == "left"))], df.train$left, sizes = c(1:9), rfeControl = control, verbose = TRUE)
print(results)
ggplot(data = results) + geom_line()
importance <- caret::varImp(results)
plot(importance)
results$bestSubset
randomForest::importance(results$fit)
results$variables
results$results
results$optVariables
results$pred
results$optsize
print(results)
ggplot(data = results) + geom_line()
vars.imp <- randomForest::importance(results$fit)
print(vars.imp)
plot(vars.imp)
ggplot(data = vars.imp)
model.rf <- randomForest::randomForest(left ~ satisfaction_level + number_project + average_montly_hours + time_spend_company
+ last_evaluation + department, data = df.train, verbose = TRUE)
View(df.train)
df.train$predicted_outcome <- predict(model.rf, newdata = df.train)
df.test$predicted_outcome <- predict(model.rf, newdata = df.test)
#Confusion matrices
conf.matrix.train <- caret::confusionMatrix(df.train$predicted_outcome, df.train$left)
conf.matrix.train
conf.matrix.test <- caret::confusionMatrix(df.test$predicted_outcome, df.test$left)
conf.matrix.test
